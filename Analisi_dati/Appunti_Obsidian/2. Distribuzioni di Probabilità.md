# Binomiale
La binomiale si usa nei casi dove ho due risultati possibili, di successo e fallimento. 
>[!def] Binomiale
> Definito:
> 	* p  -- probabilità di successo
> 	* q=1-p  -- probabilità di fallimento
> 	* n  -- ripetizioni dello sperimento
> 	* k  -- quanti eventi favorevoli su n si avrà
>  la probabilità di avere k eventi favorevoli su n ripetizioni è dato da 
>  $$
> P(k,n,p) = p^k (1-p)^{n-k} \frac{n!}{k!(n-k)!} = p^k(1-p)^{n-k} \binom{n}{k}
>$$

Per ricavare la funzione generatrice dei momenti algebrici, dobbiamo fare l'osservazione che la binomiale tratta casi discreti, quindi dovremmo usare la definizione discreta.
>[!thm] La funzione generatrice dei momenti algebrici della binomiale
> $$
> M_{k}(t) = \mathbb{E}[e^{tk}] = \sum_{k=0}^{n} e^{tk} p^k (1-p)^{n-k} \binom{n}{k} = \sum_{k=0}^{n} (e^tp)^kq^{n-k} = (pe^t+q)^n
>$$
>dove nell'ultimo passaggio si è usato il binomio di newton $(a+b)^n = \sum_{x=0}^{n}\binom{n}{x}a^xb^{n-x}$ 

Nello stesso modo si può ricavare la funzione generatrice dei momenti centrali
>[!thm] La funzione generatrice dei momenti centrali della binomiale
> $$
> \bar{M}_{x}(t) = \mathbb{E}[e^{t(k-\mu)}] = e^{t(x-\mu)}(pe^t + q)^k = (e^t(1-p)p + e^{-tp}q)^k = (pe^{qt} + qe^{-pt})^k
>$$

E una volta noti questi, possiamo ricavarci i momenti algebrici e momenti centrali derivando e valutando in t=0:
>[!mgf] I momenti algebrici della binomiale
> 1. $\mu_{0}$ non è altro che la funzione valutata in t=0 risulta essere $\mu_{0} = 1$
> 
> 2. Il valore di aspettazione risulta essere
> $$
> \mu_{1} = \left.\frac{\partial M_{x}}{\partial t} \right |_{t=0} = n(pe^t+q)^{n-1}pe^t = n(p+1-p)^{n-1}p = np
>$$

>[!central-mgf] I momenti centrali della binomiale
>3. $\bar{\mu}_{0} = 1$
>
> 4. Il valore di aspettazione momento centrale (per definizione?)
> $\bar{\mu}_{1} = 0$
> 5. Il valore di aspettazione si può calcolare usando la proprietà della varianza
> $$
> \text{var(x)} = \mathbb{E}[x^2] - \mathbb{E}[x]^2
> $$
> Derivando per la prima volta:
> $$
> \begin{gather}
> \left.\frac{\partial M_{x}}{\partial t} \right |_{t=0} = -npe^{-npt}(q+pe^t)^n + e^{-npt}n(q+pe^t)^{n-1}pe^t = \\  \\
> = ne^{-npt}(q+pe^t)^{n-1}[-p(q+pe^t) + pe^t]
> \end{gather}
>$$
>Derivando la seconda volta, otteniamo che 
> $$
> \text{var(x)} = \bar{\mu}_{2} = \left.\frac{\partial^2 M_{x}}{\partial t^2} \right |_{t=0} = np(1-p) = npq
> $$
>
> 6.  $\bar{\mu}_{3} = npq(1-2p)$
> In questo modo, se p=0.5 abbiamo che il momento terzo = 0 e allora la distribuzione è simmetrica. Mentre se p = 1, avremmo che il momento terzo è minore di zero e avrà una coda verso i x decrescenti. Se p = 0, accadrà la stessa cosa ma per x crescenti. 
> 7. $\bar{\mu}_{4} = npq(1-3pq(2-n))$

# Poisson
Mantenendo np=cost, ovvero per n->$\infty$ e p->0 si ottiene la distribuzione di Poisson. 
>[!def] La distribuzione di Poisson
>Nel caso continuo si ha che la distribuzione di Poisson 
> $$
> P(k, \nu) = \frac{\nu^k}{k!}e^{-\nu} 
> $$
